{"cells":[{"cell_type":"markdown","id":"c4a0874f","metadata":{"id":"c4a0874f"},"source":["# Operaciones con tensores\n","\n","Los tensores pueden operarse de distintas formas para producir nuevos tensores. Como otras estructuras matemáticas, los tensores permiten operaciones básicas como la suma o el producto. Otras operaciones importantes se pueden hacer con los tensores. Revisamos estas operaciones:\n","\n","### Transposición\n","\n","La transposición es una operación que se presenta en tensores de rango mayor o igual a 2. Si bien podemos pensar que un vector (tensor de rango 1) puede transponerse al considerarlo como una columna (vector en vertical) en lugar de un renglón (vector en horizontal). En el caso de las paqueterías con las que operamos la transposición de un vector no surge ningún efecto, sigue siendo un arreglo de números."]},{"cell_type":"code","execution_count":null,"id":"3d5bb2dc","metadata":{"id":"3d5bb2dc","outputId":"06e75454-d2da-4130-bdc8-68acf67831e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vector tensor([1, 2, 3])\n","Vector transpuesto: tensor([1, 2, 3])\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_6571/860429198.py:6: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3675.)\n","  print('Vector {}\\nVector transpuesto: {}'.format(x, x.T))\n"]}],"source":["import torch\n","\n","#Vector (tensro rango 1)\n","x = torch.tensor([1,2,3])\n","\n","print('Vector {}\\nVector transpuesto: {}'.format(x, x.T))"]},{"cell_type":"markdown","id":"e20582f9","metadata":{"id":"e20582f9"},"source":["En los tensores de mayor rango, la transposición es una permutación que invierte el valor de los índices de un tensor. Es decir, si el tensor $T$ tiene los índices $i_1, i_2,...,i_n$, el vector transpuesto $T^T$ tendrá los índices $i_n, i_{n-1}, ..., i_2, i_1$.\n","\n","En el caso de las <b>matrices</b>, la tranposición invierte los índices $i,j$ a $j,i$. Así, la transposición de la matriz $A$ tiene como entradas $(A^T)_{i,j} = A_{j,i}$. Es decir,m la transposición de las matrices cambia las columnas por renglones."]},{"cell_type":"code","execution_count":null,"id":"04332ccc","metadata":{"id":"04332ccc","outputId":"2589784b-a479-4ad6-bef9-390eec571c65"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0, 3, 0, 5],\n","        [5, 0, 2, 3],\n","        [1, 2, 0, 1]])\n"]}],"source":["#Tensor de rango 2 (matriz)\n","A = torch.tensor([[0, 5, 1],\n","                  [3, 0, 2],\n","                  [0, 2, 0],\n","                  [5, 3, 1]])\n","\n","print(A.T)"]},{"cell_type":"markdown","id":"4e98c8d1","metadata":{"id":"4e98c8d1"},"source":["En tensores de rango 3, los tres índices $i,j,k$ se invierten como $k,j,i$; pot ejemplo, un tensor de tamaño $(2,4,3)$ tendrá una transpuesta de tamaño $(3,4,2)$. De tal forma, que  las entradas del tensor transpuesto de grado 3 estarán dadas como: $$(T^T)_{i,j,k} = T_{k,j,i}$$"]},{"cell_type":"code","execution_count":null,"id":"39f84b7c","metadata":{"id":"39f84b7c","outputId":"f13693ab-b21f-4a73-b5b5-21cb26647e54"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor transpuesto\n","tensor([[[ 1.0000,  7.0000],\n","         [ 4.0000, 10.0000],\n","         [ 1.0000, 20.0000],\n","         [ 1.0000,  0.0000]],\n","\n","        [[ 2.0000,  8.0000],\n","         [ 5.0000, 11.0000],\n","         [ 2.0000,  1.0000],\n","         [ 0.5000,  0.0000]],\n","\n","        [[ 3.0000,  9.0000],\n","         [ 6.0000, 12.0000],\n","         [ 3.0000,  0.0000],\n","         [ 2.0000,  1.0000]]])\n","Tamaño original: torch.Size([2, 4, 3])\n","Tamaño de tranpuesta: torch.Size([3, 4, 2])\n"]}],"source":["#Tensor de rango 3\n","T = torch.tensor([[[1,2,3],[4,5,6],[1,2,3],[1,0.5,2]],\n","                  [[7,8,9],[10,11,12],[20,1,0],[0,0,1]]])\n","\n","print('Tensor transpuesto\\n{}'.format(T.T))\n","print('Tamaño original: {}\\nTamaño de tranpuesta: {}'.format(T.size(), T.T.size()))"]},{"cell_type":"code","execution_count":null,"id":"2302af3d-0d18-4323-b111-55e02a107a9e","metadata":{"id":"2302af3d-0d18-4323-b111-55e02a107a9e","outputId":"842dc65d-51a4-4561-e6d1-11d933bb9779"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 1.0000,  2.0000,  3.0000],\n","         [ 4.0000,  5.0000,  6.0000],\n","         [ 1.0000,  2.0000,  3.0000],\n","         [ 1.0000,  0.5000,  2.0000]],\n","\n","        [[ 7.0000,  8.0000,  9.0000],\n","         [10.0000, 11.0000, 12.0000],\n","         [20.0000,  1.0000,  0.0000],\n","         [ 0.0000,  0.0000,  1.0000]]])\n"]}],"source":["print(T)"]},{"cell_type":"markdown","id":"2e62c3f2","metadata":{"id":"2e62c3f2"},"source":["En tensores de mayor rango, la transposición invierte los índices de tal forma que:\n","\n","$$(T^T)_{i_1,i_2,...,i_{n-1},i_n} = T_{i_n, i_{n-1},...,i_2, i_1}$$\n","\n","Podemos generar un tensro de manera aleatoria (usamos la función <tt>torch.rand()</tt>) y ver cómo se comportan sus índices:"]},{"cell_type":"code","execution_count":null,"id":"5ac60b3e","metadata":{"id":"5ac60b3e","outputId":"1407e32f-7993-4cb2-f248-7d6f021d176f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tamaño original: torch.Size([2, 3, 4, 5, 6, 7, 8])\n","Tamaño transpuesto: torch.Size([8, 7, 6, 5, 4, 3, 2])\n"]}],"source":["#Tensor de mayor tango\n","Trank = torch.rand(2,3,4,5,6,7,8)\n","\n","print('Tamaño original: {}\\nTamaño transpuesto: {}'.format(Trank.size(), Trank.T.size()))"]},{"cell_type":"markdown","id":"6ebb318b","metadata":{"id":"6ebb318b"},"source":["### Permutaciones\n","\n","La transposición de tensores de grado mayor a 2 implica la permutación de sus dimensiones:\n","\n","$$(T_{i_1,i_2,...,i_k})^T = T_{\\sigma(i_1),\\sigma(i_2),...,\\sigma(i_k)}$$\n","Aquí $\\sigma$ es una operación de permutación. Esto permite cambiar no sólo las dimensiones finales si no cualquier dimensión entre sí. Para intercambiar las dimensiones de un tensor en PyTorch utilizamos la función <tt>transpose</tt>. Esta función como entrada toma las dos dimensiones que se van a intercambiar y regresa el tensor con estas dimensiones permutadas."]},{"cell_type":"code","execution_count":null,"id":"e1e0e47f","metadata":{"id":"e1e0e47f","outputId":"34a5ed23-f54a-4636-f5d3-820bd5002fcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 4, 3])\n","torch.Size([4, 2, 3])\n","tensor([[[ 1.0000,  2.0000,  3.0000],\n","         [ 7.0000,  8.0000,  9.0000]],\n","\n","        [[ 4.0000,  5.0000,  6.0000],\n","         [10.0000, 11.0000, 12.0000]],\n","\n","        [[ 1.0000,  2.0000,  3.0000],\n","         [20.0000,  1.0000,  0.0000]],\n","\n","        [[ 1.0000,  0.5000,  2.0000],\n","         [ 0.0000,  0.0000,  1.0000]]])\n","torch.Size([2, 3, 4])\n","tensor([[[ 1.0000,  4.0000,  1.0000,  1.0000],\n","         [ 2.0000,  5.0000,  2.0000,  0.5000],\n","         [ 3.0000,  6.0000,  3.0000,  2.0000]],\n","\n","        [[ 7.0000, 10.0000, 20.0000,  0.0000],\n","         [ 8.0000, 11.0000,  1.0000,  0.0000],\n","         [ 9.0000, 12.0000,  0.0000,  1.0000]]])\n"]}],"source":["print(T.size())\n","print(T.transpose(0,1).size())\n","print(T.transpose(0,1))\n","print(T.transpose(1,2).size())\n","print(T.transpose(1,2))"]},{"cell_type":"markdown","id":"033a2f00","metadata":{"id":"033a2f00"},"source":["### Suma de tensores\n","\n","La suma de tensores es una operación sencilla que únicamente consiste en sumar cada una de las entradas de ambos tensores. Por tanto, la suma sólo puede hacerse entre tensores del mismo rango, y de las mismas dimensiones. La suma se da como:\n","\n","$$(A + B)_{i_1,...,i_n} = A_{i_1,...,i_n} + B_{i_1,...,i_n}$$"]},{"cell_type":"code","execution_count":null,"id":"4052c712","metadata":{"id":"4052c712","outputId":"f692cf8a-6561-4587-9554-3a9099fc2115"},"outputs":[{"name":"stdout","output_type":"stream","text":["Suma de vectores\n","tensor([1, 2, 1])\n"," + \n","tensor([1, 2, 2])\n"," = \n","tensor([2, 4, 3])\n","\n","Suma de matrices\n","tensor([[0, 5, 1],\n","        [3, 0, 2],\n","        [0, 2, 0],\n","        [5, 3, 1]])\n"," + \n","tensor([[10,  0,  2],\n","        [ 9,  4,  1],\n","        [ 8,  1,  0],\n","        [ 1,  0,  0]])\n"," = \n","tensor([[10,  5,  3],\n","        [12,  4,  3],\n","        [ 8,  3,  0],\n","        [ 6,  3,  1]])\n","\n","Suma de tensores de rango 3\n","tensor([[[0.3166, 0.8017, 0.8958, 0.6522],\n","         [0.7806, 0.6851, 0.1398, 0.8946],\n","         [0.3814, 0.1044, 0.7839, 0.9801]],\n","\n","        [[0.1604, 0.6024, 0.7081, 0.1533],\n","         [0.2922, 0.2437, 0.5233, 0.9094],\n","         [0.4905, 0.0121, 0.4036, 0.4881]]])\n"," + \n","tensor([[[0.9661, 0.0314, 0.1652, 0.6337],\n","         [0.5296, 0.0596, 0.4379, 0.7087],\n","         [0.3112, 0.1103, 0.8849, 0.3673]],\n","\n","        [[0.3853, 0.6039, 0.7262, 0.4096],\n","         [0.5294, 0.2816, 0.2100, 0.2461],\n","         [0.5042, 0.2745, 0.3090, 0.1505]]])\n"," = \n","tensor([[[1.2827, 0.8332, 1.0610, 1.2859],\n","         [1.3101, 0.7446, 0.5776, 1.6033],\n","         [0.6926, 0.2147, 1.6687, 1.3473]],\n","\n","        [[0.5458, 1.2063, 1.4343, 0.5630],\n","         [0.8216, 0.5253, 0.7332, 1.1555],\n","         [0.9947, 0.2866, 0.7126, 0.6385]]])\n"]}],"source":["x = torch.tensor([1,2,1])\n","y = torch.tensor([1,2,2])\n","print('Suma de vectores')\n","print('{}\\n + \\n{}\\n = \\n{}'.format(x,y,x+y))\n","\n","\n","A = torch.tensor([[0, 5, 1],\n","                  [3, 0, 2],\n","                  [0, 2, 0],\n","                  [5, 3, 1]])\n","B = torch.tensor([[10, 0, 2],\n","                  [9, 4, 1],\n","                  [8, 1, 0],\n","                  [1, 0, 0]])\n","print('\\nSuma de matrices')\n","print('{}\\n + \\n{}\\n = \\n{}'.format(A,B,A+B))\n","\n","T1 = torch.rand(2,3,4)\n","T2 = torch.rand(2,3,4)\n","print('\\nSuma de tensores de rango 3')\n","print('{}\\n + \\n{}\\n = \\n{}'.format(T1,T2,T1+T2))"]},{"cell_type":"markdown","id":"aa38f746","metadata":{"id":"aa38f746"},"source":["### Producto por escalares\n","\n","El producto por un escalar toma un número real $\\lambda$ y multiplica cada entrada por este elemento. Por lo que las entradas de un tensor multiplicado por un escalar es de la forma $(\\lambda T)_{i_1,...,i_n} = \\lambda T_{i_1,...,i_n}$. En este sentido, lo que hace el producto por el escalar es precisamente \"escalar\" el tensor. En PyTorch, tanto como en Tensorflow y Numpy este producto se hace como:\n","\n","```python\n","  scalar = a*T\n","```\n","\n","Donde $a$ es un valor numérico, entero o flotante."]},{"cell_type":"code","execution_count":null,"id":"2e3e925e","metadata":{"id":"2e3e925e","outputId":"efbf33fd-65c2-4f4c-e373-e02ace9eeb72"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.5 • tensor([1, 2, 1])\n"," = \n","tensor([2.5000, 5.0000, 2.5000])\n","\n","2.5 • tensor([[0, 5, 1],\n","        [3, 0, 2],\n","        [0, 2, 0],\n","        [5, 3, 1]])\n"," = \n","tensor([[ 0.0000, 12.5000,  2.5000],\n","        [ 7.5000,  0.0000,  5.0000],\n","        [ 0.0000,  5.0000,  0.0000],\n","        [12.5000,  7.5000,  2.5000]])\n","2.5 • tensor([[[ 1.0000,  2.0000,  3.0000],\n","         [ 4.0000,  5.0000,  6.0000],\n","         [ 1.0000,  2.0000,  3.0000],\n","         [ 1.0000,  0.5000,  2.0000]],\n","\n","        [[ 7.0000,  8.0000,  9.0000],\n","         [10.0000, 11.0000, 12.0000],\n","         [20.0000,  1.0000,  0.0000],\n","         [ 0.0000,  0.0000,  1.0000]]])\n"," = \n","tensor([[[ 2.5000,  5.0000,  7.5000],\n","         [10.0000, 12.5000, 15.0000],\n","         [ 2.5000,  5.0000,  7.5000],\n","         [ 2.5000,  1.2500,  5.0000]],\n","\n","        [[17.5000, 20.0000, 22.5000],\n","         [25.0000, 27.5000, 30.0000],\n","         [50.0000,  2.5000,  0.0000],\n","         [ 0.0000,  0.0000,  2.5000]]])\n"]}],"source":["#Escalar\n","a = 2.5\n","\n","#Productos de tensores\n","print('{} • {}\\n = \\n{}\\n'.format(a,x, a*x))\n","print('{} • {}\\n = \\n{}'.format(a,A, a*A))\n","print('{} • {}\\n = \\n{}'.format(a,T, a*T))"]},{"cell_type":"markdown","id":"b79de374","metadata":{"id":"b79de374"},"source":["### Producto punto entre vectores\n","\n","El producto punto entre dos vectores $x, y$ de la misma dimensión se calcula como:\n","\n","$$x^T y = \\sum_{i=1}^d x_i y_i$$\n","\n","Este producto punto se realiza de diferentes formas según el lenguaje de programación que estemos usando:\n","\n","* Numpy\n","```python\n","  dot = np.dot(x,y)\n","```\n","* Tensorflow\n","```python\n","  dot = tf.tensordot(x,y)\n","```\n","* PyTorch\n","```python\n","  scalar = torch.matmul(x,y)\n","```"]},{"cell_type":"code","execution_count":null,"id":"4ec26fdd","metadata":{"id":"4ec26fdd","outputId":"7d98a49d-34a0-482c-dea0-90539a964711"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 1]) • tensor([1, 2, 2])\n"," = \n","7\n"]}],"source":["#Producto punto\n","dot = torch.matmul(x,y)\n","\n","print('{} • {}\\n = \\n{}'.format(x,y, dot))"]},{"cell_type":"markdown","id":"b572205e","metadata":{"id":"b572205e"},"source":["### Productos con matrices\n","\n","Los tensores de rango 2 pueden multiplicar a otros tensores de diferente rango. Por ejemplo, se puede realizar el producto entre una matriz $A$ y un vector $x$ donde la dimensiones de las columnas de $A$ deben coincidir con la dimensión de $x$. El resultado de producto es un vector que está determinado como:\n","\n","$$(Ax)_i = \\sum_j A_{i,j} x_j$$\n","\n","En este caso, se utilizan las mismas funciones que en el producto punto. En este caso, tenemos la función <tt>torch.matmul()</tt>."]},{"cell_type":"code","execution_count":null,"id":"4036d85c","metadata":{"id":"4036d85c","outputId":"d7cd8cf5-6429-4767-da0e-66d031526ad4"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0, 5, 1],\n","        [3, 0, 2],\n","        [0, 2, 0],\n","        [5, 3, 1]]) • tensor([1, 2, 1])\n"," = \n","tensor([11,  5,  4, 12])\n"]}],"source":["#Producto matriz con vector\n","product = torch.matmul(A,x)\n","\n","print('{} • {}\\n = \\n{}'.format(A,x, product))"]},{"cell_type":"markdown","id":"516d9465","metadata":{"id":"516d9465"},"source":["Asimismo, se puede realizar el producto entre dos matrices que compartan una dimensión. Es decir, la primera matriz tendrá tantas columnas como renglones la segunda. El producto entre matrices está dado como:\n","\n","$$(AB)_{i,j} = \\sum_k A_{i,k} B_{k,j}$$"]},{"cell_type":"code","execution_count":null,"id":"c859655b","metadata":{"id":"c859655b","outputId":"022d38b4-e5f1-4bb3-9277-14c6c85df8bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0, 5, 1],\n","        [3, 0, 2],\n","        [0, 2, 0],\n","        [5, 3, 1]])\n","  •  \n","tensor([[10,  9,  8,  1],\n","        [ 0,  4,  1,  0],\n","        [ 2,  1,  0,  0]])\n"," = \n","tensor([[ 2, 21,  5,  0],\n","        [34, 29, 24,  3],\n","        [ 0,  8,  2,  0],\n","        [52, 58, 43,  5]])\n"]}],"source":["#Producto matriz con vector\n","rank2_product = torch.matmul(A,B.T)\n","\n","print('{}\\n  •  \\n{}\\n = \\n{}'.format(A,B.T, rank2_product))"]},{"cell_type":"markdown","id":"d4c126db","metadata":{"id":"d4c126db"},"source":["### Producto entre tensores de mayor rango\n","\n","Los tensores de rango 3 o mayores pueden multiplicarse con otros tensores de menor o igual rango. Por ejemplo, podemos multiplicar un vector de rango 3 por un vector como:\n","\n","$$(Tx)_{i,j} = \\sum_{k} T_{i,j,k} x_k$$\n","\n","Por su parte, también podemos multiplicar el tensor por una matriz, de la siguiente forma:\n","\n","$$(TA)_{i,j,k} = \\sum_{l} T_{i,j,l} A_{l,k}$$"]},{"cell_type":"code","execution_count":null,"id":"2cf56d00","metadata":{"id":"2cf56d00","outputId":"f81c0d34-7e31-43d8-ad74-a5add69c9140"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensor de rango 3 por vector\n","tensor([[[0.6671, 0.1755, 0.5040],\n","         [0.2246, 0.5768, 0.5452],\n","         [0.8690, 0.5665, 0.9571]],\n","\n","        [[0.0749, 0.5613, 0.0696],\n","         [0.9162, 0.5287, 0.5936],\n","         [0.9260, 0.4972, 0.0025]],\n","\n","        [[0.0705, 0.8585, 0.0400],\n","         [0.9990, 0.4045, 0.3715],\n","         [0.8124, 0.6755, 0.0536]]])\n","  •  \n","tensor([0.6827, 0.6488, 0.5703])\n"," = \n","tensor([[0.8567, 0.8384, 1.5065],\n","        [0.4550, 1.3070, 0.9562],\n","        [0.6279, 1.1563, 1.0233]])\n","\n","\n","Tensor de rango 3 por matriz\n","tensor([[[0.6671, 0.1755, 0.5040],\n","         [0.2246, 0.5768, 0.5452],\n","         [0.8690, 0.5665, 0.9571]],\n","\n","        [[0.0749, 0.5613, 0.0696],\n","         [0.9162, 0.5287, 0.5936],\n","         [0.9260, 0.4972, 0.0025]],\n","\n","        [[0.0705, 0.8585, 0.0400],\n","         [0.9990, 0.4045, 0.3715],\n","         [0.8124, 0.6755, 0.0536]]])\n","  •  \n","tensor([[0.0245, 0.6982],\n","        [0.6182, 0.1792],\n","        [0.3382, 0.4807]])\n"," = \n","tensor([[[0.2953, 0.7395],\n","         [0.5465, 0.5222],\n","         [0.6952, 1.1683]],\n","\n","        [[0.3724, 0.1863],\n","         [0.5501, 1.0197],\n","         [0.3310, 0.7369]],\n","\n","        [[0.5460, 0.2223],\n","         [0.4002, 0.9486],\n","         [0.4556, 0.7140]]])\n"]}],"source":["#Crea tensores\n","T = torch.rand(3,3,3)\n","A = torch.rand(3,2)\n","x = torch.rand(3,)\n","\n","#Producto por vector\n","vector_product = torch.matmul(T,x)\n","#Producto por matriz\n","matrix_product = torch.matmul(T,A)\n","\n","print('Tensor de rango 3 por vector')\n","print('{}\\n  •  \\n{}\\n = \\n{}'.format(T,x, vector_product))\n","print('\\n\\nTensor de rango 3 por matriz')\n","print('{}\\n  •  \\n{}\\n = \\n{}'.format(T,A, matrix_product))"]},{"cell_type":"markdown","id":"6299a47e","metadata":{"id":"6299a47e"},"source":["Finalmente, podemos realizar el producto entre tensores de mayor rango. Por ejemplo, entre tensores de rango 3. En todos estos casos, como vemos, se utiliza la función <tt>torch.matmul()</tt>."]},{"cell_type":"code","execution_count":null,"id":"2c07e1d5","metadata":{"id":"2c07e1d5","outputId":"a6d0b265-abc4-4bf1-ebe9-845da69c1393"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[0.6671, 0.1755, 0.5040],\n","         [0.2246, 0.5768, 0.5452],\n","         [0.8690, 0.5665, 0.9571]],\n","\n","        [[0.0749, 0.5613, 0.0696],\n","         [0.9162, 0.5287, 0.5936],\n","         [0.9260, 0.4972, 0.0025]],\n","\n","        [[0.0705, 0.8585, 0.0400],\n","         [0.9990, 0.4045, 0.3715],\n","         [0.8124, 0.6755, 0.0536]]])\n","  •  \n","tensor([[[0.8544, 0.9633, 0.8964],\n","         [0.2056, 0.5180, 0.6232],\n","         [0.4392, 0.4433, 0.9418]],\n","\n","        [[0.2497, 0.6056, 0.7493],\n","         [0.6232, 0.3731, 0.2040],\n","         [0.3986, 0.0691, 0.1820]],\n","\n","        [[0.0226, 0.9946, 0.6573],\n","         [0.8132, 0.9677, 0.9797],\n","         [0.2124, 0.7527, 0.1495]]])\n"," = \n","tensor([[[0.8275, 0.9570, 1.1821],\n","         [0.5499, 0.7568, 1.0742],\n","         [1.2793, 1.5548, 2.0333]],\n","\n","        [[0.3963, 0.2596, 0.1833],\n","         [0.7949, 0.7931, 0.9024],\n","         [0.5421, 0.7465, 0.7958]],\n","\n","        [[0.7082, 0.9310, 0.8934],\n","         [0.4304, 1.6647, 1.1085],\n","         [0.5790, 1.5020, 1.2038]]])\n"]}],"source":["#Crea un tensor de rango 3\n","T2 = torch.rand(3,3,3)\n","#Producto entre tensores\n","rank3_product = torch.matmul(T,T2)\n","\n","print('{}\\n  •  \\n{}\\n = \\n{}'.format(T,T2, rank3_product))"]},{"cell_type":"markdown","id":"525c8192","metadata":{"id":"525c8192"},"source":["### Producto de Hadamard\n","\n","El producto de Hadamard es un producto punto a punto, en donde cada entrada de los tensores se multiplican entre si. Es decir, se tiene que:\n","\n","$$(T \\odot U)_{i_1,...,i_n} = T_{i_1,...,i_n}U_{i_1,...,i_n}$$\n","\n","Este producto suele hacerse por medio del operador <tt>*</tt>."]},{"cell_type":"code","execution_count":null,"id":"9e257bfd","metadata":{"id":"9e257bfd","outputId":"6f3992f3-d5d7-402d-e787-6e914b527a1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.6827, 0.6488, 0.5703])\n","  o  \n","tensor([1, 2, 2])\n"," = \n","tensor([0.6827, 1.2975, 1.1406])\n"]}],"source":["#Producto punto a punto\n","had = x*y\n","\n","print('{}\\n  o  \\n{}\\n = \\n{}'.format(x,y, had))"]},{"cell_type":"markdown","id":"375910c3","metadata":{"id":"375910c3"},"source":["### Producto externo\n","\n","El producto externo es importante para algunas operaciones entre vectores, pues produce una matriz cuyas entradas son productos entre los elementos de ambos vectores. En este caso, el resultado se obtiene como:\n","\n","$$(x \\otimes y)_{i,j} = x_i y_j $$"]},{"cell_type":"code","execution_count":null,"id":"1d3fdaee","metadata":{"id":"1d3fdaee","outputId":"74f3226a-2325-4e34-b8b7-94fdc41be75e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.6827, 0.6488, 0.5703])\n","  x  \n","tensor([1, 2, 2])\n"," = \n","tensor([[0.6827, 1.3653, 1.3653],\n","        [0.6488, 1.2975, 1.2975],\n","        [0.5703, 1.1406, 1.1406]])\n"]}],"source":["#Producto externo\n","outer = torch.outer(x,y)\n","\n","print('{}\\n  x  \\n{}\\n = \\n{}'.format(x,y, outer))"]},{"cell_type":"markdown","id":"449d50ce","metadata":{"id":"449d50ce"},"source":["     "]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[{"file_id":"1ERSvWkzyelkrKMh36EeRcjBeTLFVN3aq","timestamp":1749862819483}]}},"nbformat":4,"nbformat_minor":5}