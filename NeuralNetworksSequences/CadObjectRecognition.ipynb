{"cells":[{"cell_type":"code","execution_count":null,"id":"e74084f9","metadata":{"id":"e74084f9"},"outputs":[],"source":["import os\n","import shutil\n","import pickle\n","import subprocess\n","from pathlib import Path\n","from typing import Literal, List\n","\n","import torch\n","import numpy as np\n","import trimesh\n","import matplotlib.pyplot as plt\n","from trimesh.voxel import VoxelGrid\n","from mpl_toolkits.mplot3d import Axes3D"]},{"cell_type":"markdown","id":"43b891fa","metadata":{"id":"43b891fa"},"source":["## Redes Neuronales Recurrentes: Clasificación de Models CAD"]},{"cell_type":"markdown","id":"d88dcf45","metadata":{"id":"d88dcf45"},"source":["En este cuaderno de Jupyer abordaremos el problema de entrenar una red neuronal convolucional tridimensional (3D-CNN) para clasificar modelos de objetos CAD provenientes del conjunto de datos ModelNet10. Utilizaremos la biblioteca trimesh de Python para manipular estos modelos, y la herramienta binvox para transformarlos en una representación voxelizada adecuada para su procesamiento con la 3D-CNN. Al final, evaluaremos y visualizaremos los resultados utilizando matplotlib.\n","\n","1. Construcción de conjunto de datos ModelNet10Binvox\n","    - Explicación del conjunto de entrenmiento.\n","    - Lectura del conjunto y procesamiento de conjunto de datos.\n","    - Voxelización utilizando Binvox.\n","2. Entrenamiento de Modelo\n","    - Construcción de conjunto de datos para entrenamiento.\n","    - Definición de DataLoader y TensorDataset.\n","    - Entrenamiento registrando la exactitud y la perdida.\n","3. Análisis de resultados\n","    - Evaluación en el conjunto de pruebas para analizar el poder de generalización del modelo.\n","    - Demostración de algunas inferencias utilizando matplotlib para renderizar los modelos."]},{"cell_type":"markdown","id":"4d1aea3f","metadata":{"id":"4d1aea3f"},"source":["# 1. Construcción de conjunto de datos ModelNet10Binvox"]},{"cell_type":"markdown","id":"28e4f742","metadata":{"id":"28e4f742"},"source":["La estructura de directorio de ModelNet10 se compone de 10 carpetas representando cada categoría de objeto. Dentro de cada una de estas carpetas se encuentras otras dos con los datos de entrenamiento y prueba repectivamente. Las diez categorías del conjunto de datos son bathtub, bed, chair, desk, dresser, monitor, night_stand, sofa, table y toilet.\n","\n","- ModelNet10\n","    - bathtub\n","        - test\n","            - ...\n","        - train\n","            - ...\n","    - bed\n","        - test\n","            - ...\n","        - train\n","            - ...\n","    - ...\n","\n","Vamos a construir un conjunto de datos ModelNet10Binvox que va a contener los modelos voxelizados. Su estructua va a ser más sencilla y solo tendrá dos directorios uno con los modelos de entrenamiento y otro con los de prueba. Las clases de los objetos se pueden distinguir todavía con el nombre del archivo.\n","\n","\n","- ModelNet10Binvox\n","    - train\n","        - ...\n","    - test\n","        - ...\n"]},{"cell_type":"code","execution_count":null,"id":"d6170d59","metadata":{"id":"d6170d59"},"outputs":[],"source":["class BinvoxDatasetBuilder:\n","    def __init__(self, input_directory: str, output_directory: str) -> None:\n","        \"\"\" Clase para generar el conjunto ModelNet10Binvox.\n","        :param input_directory: Ruta del directorio que contiene los conjuntos de datos de ModelNet.\n","        :param output_directory: Ruta del directorio donde se almacenarán los conjuntos de datos procesados.\n","            El directorio debe de existir.\n","        \"\"\"\n","        self._input_directory = input_directory\n","        self._output_directory = output_directory\n","\n","    def execute(self) -> None:\n","        \"\"\"Genera el conjunto de datos.\"\"\"\n","        for split in [\"train\", \"test\"]:\n","            file_paths = self._list_dataset_file_paths(split)\n","            for path in file_paths:\n","                self._process_binvox(path, os.path.join(self._output_directory, split))\n","\n","    def _list_dataset_file_paths(self, split: Literal[\"train\", \"test\"]) -> List[str]:\n","        \"\"\"Enumera las rutas absolutas de los archivos del conjunto de datos de entrenamiento o pruebas del\n","        dataset \"ModelNet10\".\n","\n","        :param dataset_directory_path: Ruta del directorio que contiene los conjuntos de datos.\n","        :param split: Define si se deben listar los archivos del conjunto de datos de entrenamiento o prueba.\n","        :return: Una lista de cadenas de texto donde cada cadena es una ruta a un archivo en el conjunto de datos\n","            solicitado.\n","        \"\"\"\n","        files_paths = []\n","        objects_paths = [p for p in Path(self._input_directory).iterdir() if p.is_dir()]\n","        for op in objects_paths:\n","            paths = [str(path) for path in Path(op / split).iterdir() if path.is_file()]\n","            files_paths.extend(paths)\n","        return files_paths\n","\n","    def _process_binvox(self, file_path: str, output_dir: str) -> VoxelGrid:\n","        \"\"\"Procesa un modelo cad con binvox y lo mueve al directorio de salida especificado.\n","\n","        :param file_path: Ruta al archivo con extensión .off a procesar.\n","        :param output_dir: Ruta del directorio donde se almacenará el archivo .binvox procesado.\n","        \"\"\"\n","        output_file_name = os.path.splitext(os.path.basename(file_path))[0] + \".binvox\"\n","        default_output_path = os.path.join(os.path.dirname(file_path), output_file_name)\n","        output_path = os.path.join(output_dir, output_file_name)\n","        cmd = [\"/ruta/hacia/binvox\", \"-d\", \"32\", \"-cb\", file_path]\n","        output = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","        shutil.move(default_output_path, output_path)\n"]},{"cell_type":"code","source":["# Uso de la clase para generar conjunto ModelNet10Binvox\n","dataset_builder = BinvoxDatasetBuilder(\n","    input_directory=\"/ruta/hacia/ModelNet10\",\n","    output_directory=\"/ruta/hacia/ModelNet10Binvox\"\n",")"],"metadata":{"id":"1Afx9ZAnkNa1"},"id":"1Afx9ZAnkNa1","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"486845a4","metadata":{"id":"486845a4"},"source":["# 2. Entrenamiento de Modelo"]},{"cell_type":"markdown","id":"07a0ec0d","metadata":{"id":"07a0ec0d"},"source":["El conjunto ModelNet10Binvox nos ayuda a tener una referencia de los modelos voxelizados; sin embargo, no se puede usar directamente para entrena la red convolucional, para esto, tenemos que convertir los modelos de formato .binvox a tendores.\n","\n","El objetivo es crear 4 tensores:\n","- train_matrix: Contiene la representación tensorial de los modelos, tiene dimensiones (3991, 38, 38, 38)\n","- train_labels: Contiene la representación numérica de la clase del modelo, tiene dimensiones (3991, )\n","- test_matrix: Contiene la representación tensorial de los modelos, tiene dimensiones (908, 38, 38, 38)\n","- test_labels: Contiene la representación numérica de la clase del modelo, tiene dimensiones (908, )\n","\n","Los modelos de binvox tienen dimensiones (32, 32, 32) pero aquí los convertimos a (38, 38, 38) en donde se les agrega padding lleno de zeros en las tres dimensiones con el objetivo de no perder información de las esquinas."]},{"cell_type":"code","execution_count":null,"id":"b60b1d90","metadata":{"scrolled":true,"id":"b60b1d90"},"outputs":[],"source":["# La variable \"categories\" nos ayudará a convertir una categoría de su representación numérica a su representación\n","# como palabra y viceversa. La conversión se realiza utilizando el índice de la palabra e.g. la representación\n","# numérica de \"table\" es 8. La palabra \"night\" se refiere a \"night_stand\"\n","categories = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night\", \"sofa\", \"table\", \"toilet\"]\n","\n","# Construcción del conjunto de entrenamiento\n","binxov_path = \"/ruta/hacia/ModelNet10Binvox/train\"\n","num_train_files = len(os.listdir(binxov_path))\n","train_matrix = torch.zeros((num_train_files, 38, 38, 38), dtype=torch.float32)\n","train_labels = torch.empty((num_train_files,), dtype=torch.uint8)\n","for i, file in enumerate(os.scandir(binxov_path)):\n","    print(f\"i, file.path: {i}, {file.path}\")\n","    with open(file.path, \"rb\") as f:\n","        voxel_grid = trimesh.exchange.binvox.load_binvox(f)\n","    train_labels[i] = categories.index(file.name.split(\"_\")[0])\n","    train_matrix[i, 3:-3, 3:-3, 3:-3] = torch.tensor(voxel_grid.matrix)\n","torch.save(train_matrix, \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/train.pt\")\n","torch.save(train_labels, \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/train_labels.pt\")\n","\n","# Construcción del conjunto de pruebas\n","binxov_path = \"/ruta/hacia/ModelNet10Binvox/test\"\n","num_test_files = len(os.listdir(binxov_path))\n","test_matrix = torch.zeros((num_test_files, 38, 38, 38), dtype=torch.float32)\n","test_labels = torch.empty((num_test_files,), dtype=torch.uint8)\n","for i, file in enumerate(os.scandir(binxov_path)):\n","    print(f\"i, file.path: {i}, {file.path}\")\n","    with open(file.path, \"rb\") as f:\n","        voxel_grid = trimesh.exchange.binvox.load_binvox(f)\n","    test_labels[i] = categories.index(file.name.split(\"_\")[0])\n","    test_matrix[i, 3:-3, 3:-3, 3:-3] = torch.tensor(voxel_grid.matrix)\n","torch.save(test_labels, \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/test_labels.pt\")\n","torch.save(test_matrix, \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/test.pt\")"]},{"cell_type":"code","execution_count":null,"id":"ff978c02","metadata":{"id":"ff978c02"},"outputs":[],"source":["# Cargar los datos precomputados\n","train_matrix = torch.load(\"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/train.pt\")\n","train_labels = torch.load(\"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/train_labels.pt\")\n","test_matrix = torch.load(\"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/test.pt\")\n","test_labels = torch.load(\"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Pytorch/test_labels.pt\")"]},{"cell_type":"code","execution_count":null,"id":"91d180e2","metadata":{"id":"91d180e2","outputId":"08acbbb9-99ff-4ffb-db54-1b4e49d3b56c"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_matrix.shape: torch.Size([3991, 38, 38, 38])\n","train_labels.shape: torch.Size([3991])\n","test_matrix.shape: torch.Size([908, 38, 38, 38])\n","test_labels.shape: torch.Size([908])\n"]}],"source":["print(f\"train_matrix.shape: {train_matrix.shape}\")\n","print(f\"train_labels.shape: {train_labels.shape}\")\n","print(f\"test_matrix.shape: {test_matrix.shape}\")\n","print(f\"test_labels.shape: {test_labels.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"0e0bc50e","metadata":{"id":"0e0bc50e"},"outputs":[],"source":["class CadNet(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Tensor de entrada tiene dimensiones (batch_size, 1 38, 38, 38)\n","        self.conv_layers = torch.nn.Sequential(\n","            torch.nn.Conv3d(\n","                in_channels=1,\n","                out_channels=32,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ), # (batch_size, 32, 38, 38, 38)\n","            torch.nn.ReLU(inplace=True),\n","            torch.nn.MaxPool3d(kernel_size=2, stride=2),  # (batch_size, 32, 19, 19, 19)\n","\n","            torch.nn.Conv3d(\n","                in_channels=32,\n","                out_channels=64,\n","                kernel_size=3,\n","                stride=1,\n","                padding=1\n","            ),  # (batch_size, 64, 19, 19, 19)\n","            torch.nn.ReLU(inplace=True),\n","            torch.nn.MaxPool3d(kernel_size=2, stride=2),  # (batch_size, 64, 9, 9, 9)\n","        )\n","\n","        self.fc_layers = torch.nn.Sequential(\n","            torch.nn.Linear(64 * 9 * 9 * 9, 512),\n","            torch.nn.ReLU(inplace=True),\n","            torch.nn.Dropout(),\n","            torch.nn.Linear(512, 10)\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)\n","        x = x.view(x.size(0), -1) # flatten tensor\n","        x = self.fc_layers(x)\n","        return x  # (batch_size, 10)"]},{"cell_type":"code","execution_count":null,"id":"341168a5","metadata":{"id":"341168a5","outputId":"ea5e45a9-9da5-4b0c-8ae3-ebeb3fe4d0fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_matrix.shape: torch.Size([3991, 1, 38, 38, 38])\n","test_matrix.shape: torch.Size([908, 1, 38, 38, 38])\n"]}],"source":["# Las convoluciones 3D esperan una entrada con dimensiones (batch_size, channels, depth, height, width), por lo que\n","# tenemos que agregar la dimensión \"channels\"\n","train_matrix = train_matrix.unsqueeze(1)\n","test_matrix = test_matrix.unsqueeze(1)\n","print(f\"train_matrix.shape: {train_matrix.shape}\")\n","print(f\"test_matrix.shape: {test_matrix.shape}\")"]},{"cell_type":"code","execution_count":null,"id":"0604a4a6","metadata":{"id":"0604a4a6"},"outputs":[],"source":["# Utilizamos TensorDataset para generar el conjunto de datos, de acuerdo a la documentación oficial \"Cada muestra se\n","# recuperará indexando tensores a lo largo de la primera dimensión\". También generamos los DataLoaders con un tamaño\n","# de bache de 64.\n","train_data = torch.utils.data.TensorDataset(train_matrix, train_labels)\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","\n","test_data = torch.utils.data.TensorDataset(test_matrix, test_labels)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)"]},{"cell_type":"code","execution_count":null,"id":"47baeb4a","metadata":{"scrolled":true,"id":"47baeb4a","outputId":"b4238f23-d53b-4eb6-9795-ca96f4aff4a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.3834688663482666, Accuracy: 80.20546229015284%\n","Epoch 2, Loss: 0.12099435180425644, Accuracy: 91.15509897268855%\n","Epoch 3, Loss: 0.11604078859090805, Accuracy: 93.43522926584816%\n","Epoch 4, Loss: 0.18583758175373077, Accuracy: 94.23703332498121%\n","Epoch 5, Loss: 0.07984792441129684, Accuracy: 95.26434477574543%\n","Epoch 6, Loss: 0.10109993815422058, Accuracy: 96.51716361814081%\n","Epoch 7, Loss: 0.0355650894343853, Accuracy: 96.4419944875971%\n","Epoch 8, Loss: 0.06436997652053833, Accuracy: 96.96817840140315%\n","Epoch 9, Loss: 0.19982895255088806, Accuracy: 97.76998246053621%\n","Epoch 10, Loss: 0.013670407235622406, Accuracy: 97.64470057629667%\n"]}],"source":["device = torch.device('cpu')\n","model = CadNet().to(device)\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","loss_history = []\n","accuracy_history = []\n","for epoch in range(10):  # Se entrena por diez épocas\n","    # Correct y total se utilizand para calcular la exactitud\n","    correct = 0\n","    total = 0\n","    total_loss = 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # Propagación hacia adelante\n","        outputs = model(inputs)  # (batch_size, categories)\n","        loss = criterion(outputs, labels)  # Make sure labels are long type\n","        total_loss += loss\n","\n","        # Calcular la exactitud\n","        # torch.max regresa una tupla de (valores, índices) en donde para cada fila especificada por\n","        # el argumento dimensión se regresa el valor máximo y los índices de estos.\n","        _, predicted = torch.max(outputs, dim=1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        # Retropropagación\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    accuracy = 100 * correct / total\n","    accuracy_history.append(accuracy)\n","    loss_history.append(total_loss / total)\n","    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}, Accuracy: {accuracy}%\")\n","\n","torch.save(model.state_dict(), 'model_state_dict.pt')\n","with open(\"accuracy_history.pkl\", \"wb\") as f:\n","    pickle.dump(accuracy_history, f)"]},{"cell_type":"markdown","id":"abb97787","metadata":{"id":"abb97787"},"source":["# 3. Análisis de resultados"]},{"cell_type":"code","execution_count":null,"id":"5ec0fc92","metadata":{"id":"5ec0fc92"},"outputs":[],"source":["# Cargar el modelo y el historial de la exactitud\n","model = CadNet()\n","model.load_state_dict(torch.load('model_state_dict.pt'))\n","with open(\"accuracy_history.pkl\", \"rb\") as f:\n","    accuracy_history = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"id":"4b6f9229","metadata":{"id":"4b6f9229"},"outputs":[],"source":["# Graficar la progresión de la exactitud\n","epochs = range(1, len(accuracy_history) + 1)\n","plt.figure(figsize=(10, 6))\n","plt.plot(epochs, accuracy_history, \"b\", label=\"Training accuracy\")\n","plt.plot(epochs, accuracy_history, \"b\", label=\"Training accuracy\")\n","plt.title(\"Exactitud por época\", fontsize=16)\n","plt.xlabel(\"Época\", fontsize=14)\n","plt.ylabel(\"Exactitud\", fontsize=14)\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"a67d9853","metadata":{"id":"a67d9853"},"outputs":[],"source":["# Obtener exactitud en conjunto de pruebas\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","\n","        outputs = model(inputs)\n","\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","accuracy = 100 * correct / total\n","print(f\"Accuracy on test set: {accuracy:.2f}%\")"]},{"cell_type":"code","execution_count":null,"id":"273bc747","metadata":{"id":"273bc747"},"outputs":[],"source":["def classify_model(model_path: str, model: torch.nn.Module) -> str:\n","    \"\"\"Clasifica un objeto 3D utilizando un modelo preentrenado.\n","\n","    Esta función carga los datos de voxel de un archivo .binvox, los prepara para la entrada al\n","    modelo proporcionado, realiza un pase hacia adelante del modelo, y devuelve la categoría del\n","    objeto 3D.\n","\n","    :param model_path: Ruta al archivo .binvox que contiene los datos de voxel para el objeto 3D.\n","    :param model: El modelo PyTorch preentrenado a utilizar para la tarea de clasificación.\n","    :return: La categoría del objeto 3D, según la identifica el modelo.\n","    \"\"\"\n","    with open(model_path, \"rb\") as f:\n","        voxel_data = trimesh.exchange.binvox.load_binvox(f).matrix\n","    input = torch.zeros((1, 1, 38 ,38, 38))\n","    input[0, 0, 3:-3, 3:-3, 3:-3] = torch.tensor(voxel_data)\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(input)\n","        # torch.argmax devuelve los índices de los valores máximos de un tensor a lo largo de una dimensión.\n","        class_index = torch.argmax(output)\n","    categories = [\"bathtub\", \"bed\", \"chair\", \"desk\", \"dresser\", \"monitor\", \"night\", \"sofa\", \"table\", \"toilet\"]\n","    return categories[class_index.item()]\n","\n","\n","def plot_model(model_path: str) -> None:\n","    \"\"\"Grafica el modelo voxelizado.\"\"\"\n","    with open(model_path, \"rb\") as f:\n","        voxel_data = trimesh.exchange.binvox.load_binvox(f).matrix\n","\n","    # Prepare some coordinates\n","    x, y, z = np.indices(np.array(voxel_data.shape) + 1)\n","\n","    # Draw the voxels\n","    voxels = voxel_data\n","\n","    # Choose colors for each voxel\n","    colors = np.empty(voxels.shape, dtype=object)\n","    colors[voxels] = 'blue'  # Color the True voxels\n","\n","    # Plot everything\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111, projection='3d')\n","    ax.voxels(x, y, z, voxels, facecolors=colors, edgecolors='k', linewidth=0.5, alpha=0.8)\n"]},{"cell_type":"code","execution_count":null,"id":"d6417028","metadata":{"id":"d6417028"},"outputs":[],"source":["model_path = \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Binvox/test/bathtub_0107.binvox\"\n","category = classify_model(model_path, model)\n","print(f\"category: {category}\")\n","plot_model(model_path)"]},{"cell_type":"code","execution_count":null,"id":"9e185cde","metadata":{"id":"9e185cde"},"outputs":[],"source":["model_path = \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Binvox/test/chair_0891.binvox\"\n","category = classify_model(model_path, model)\n","print(f\"category: {category}\")\n","plot_model(model_path)"]},{"cell_type":"code","execution_count":null,"id":"7a427c90","metadata":{"id":"7a427c90"},"outputs":[],"source":["model_path = \"/home/kosmos/artur/unam/cad_object_recognition/ModelNet10Binvox/test/sofa_0757.binvox\"\n","category = classify_model(model_path, model)\n","print(f\"category: {category}\")\n","plot_model(model_path)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}